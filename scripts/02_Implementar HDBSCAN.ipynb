{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. CARGA DE LIBRERÍAS\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import hdbscan\n",
    "import shapely\n",
    "import alphashape\n",
    "from shapely.geometry import MultiPoint, Point, Polygon, MultiPolygon\n",
    "from shapely import concave_hull\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. DEFINIR VARIABLES GLOBALES\n",
    "region = \"R12\"\n",
    "gdb_in = \"datos_input/APC2023_\" + region + \".gdb\"\n",
    "gdb_out = \"datos_output/GIS_resultados_entrega_1.gdb\"\n",
    "fc_in = region + \"_puntos_edificacion_rural\"\n",
    "fc_viviendas_out = region + \"_viviendas_py\"\n",
    "fc_clusters_out = region + \"_cl_hull_py\"\n",
    "minViv = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. CARGA DE DATOS\n",
    "viviendas = gpd.read_file(filename = gdb_in, layer = fc_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. SELECCIONAR VARIABLES CLUSTERING\n",
    "xy_data = viviendas[[\"POINT_X\", \"POINT_Y\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. EJECUTAR DBSCAN\n",
    "cluster_hdb = hdbscan.HDBSCAN(min_cluster_size = minViv,\n",
    "                              min_samples = minViv,\n",
    "                              core_dist_n_jobs = 22,\n",
    "                            #   prediction_data=True\n",
    "                              ).fit(xy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. PEGAR RESULTADOS A CAPA VIVIENDAS\n",
    "# viviendas[\"id_cluster\"] = np.where(cluster_hdb.labels_ == -1, np.nan, cluster_hdb.labels_ + 1)\n",
    "viviendas[\"id_cluster\"] = np.where(cluster_hdb.labels_ == -1, np.nan, cluster_hdb.labels_ + 1)\n",
    "viviendas[\"membership_prob\"] = cluster_hdb.probabilities_\n",
    "viviendas[\"outlier_score\"]   = cluster_hdb.outlier_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. AJUSTAR CLUSTERS SEGÚN OLTIER SCORE (> quantil 0.9)\n",
    "viviendas[\"id_cluster_final\"] = np.where(\n",
    "    viviendas[\"outlier_score\"] > 0.9,\n",
    "    np.nan,\n",
    "    viviendas[\"id_cluster\"]\n",
    ")\n",
    "\n",
    "\n",
    "## Calcular el umbral como el percentil 90 de los outlier scores\n",
    "# umbral = viviendas[\"outlier_score\"].quantile(0.9)\n",
    "\n",
    "\n",
    "# ## Marcar como outlier si supera ese umbral\n",
    "# viviendas[\"es_outlier\"] = viviendas[\"outlier_score\"] > umbral_outlier\n",
    "# viviendas[\"umbral_region\"] = umbral\n",
    "\n",
    "# ## Transformar a NA los id_cluster que sobrepase umbral\n",
    "# viviendas[\"id_cluster_final\"] = np.where(\n",
    "#     viviendas[\"outlier_score\"] > umbral_outlier,\n",
    "#     np.nan,\n",
    "#     viviendas[\"id_cluster\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. CALCULAR CONCAVE HULL POR CLUSTER\n",
    "viviendas_cl = viviendas.dropna(subset=[\"id_cluster_final\"]).copy()\n",
    "\n",
    "# Crear lista de resultados\n",
    "poligonos2 = []\n",
    "\n",
    "# Agrupar por ID y aplicar concave_hull\n",
    "for group_id, group in viviendas_cl.groupby(\"id_cluster_final\"):\n",
    "    puntos = [geom for geom in group.geometry if isinstance(geom, Point)]\n",
    "    if len(puntos) < 4:\n",
    "        continue\n",
    "    multipunto = MultiPoint(puntos)\n",
    "    try:\n",
    "        hull = concave_hull(multipunto, ratio=0.5)\n",
    "        poligonos2.append({\"id_cluster_final\": group_id, \"geometry\": hull})\n",
    "    except Exception as e:\n",
    "        print(f\"Error en grupo {group_id}: {e}\")\n",
    "\n",
    "# Crear GeoDataFrame y guardar\n",
    "if poligonos2:\n",
    "    cluster_hulls = gpd.GeoDataFrame(poligonos2, geometry=\"geometry\", crs=viviendas.crs)\n",
    "    # gdf_hulls.to_file(\"concave_hulls_por_id.gpkg\", layer=\"hullsdep\", driver=\"GPKG\")\n",
    "else:\n",
    "    print(\"No se generaron polígonos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. CALCULAR STATS POR CLUSTER\n",
    "stats_cluster = viviendas.dropna(subset=[\"id_cluster_final\"]).groupby(\"id_cluster_final\").agg(\n",
    "    n_viviendas     = (\"id_cluster_final\", \"count\"),\n",
    "    membership_mean = (\"membership_prob\", \"mean\"),\n",
    "    membership_std  = (\"membership_prob\", \"std\"),\n",
    "    membership_min  = (\"membership_prob\", \"min\"),\n",
    "    membership_max  = (\"membership_prob\", \"max\"),\n",
    "    outlier_mean = (\"outlier_score\", \"mean\"),\n",
    "    outlier_std  = (\"outlier_score\", \"std\"),\n",
    "    outlier_min  = (\"outlier_score\", \"min\"),\n",
    "    outlier_max  = (\"outlier_score\", \"max\")\n",
    ").reset_index()\n",
    "stats_cluster[\"persistence\"] = cluster_hdb.cluster_persistence_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. JOIN STATS A CONCAVE HULL\n",
    "cluster_hulls_final = pd.merge(cluster_hulls, stats_cluster, on = \"id_cluster_final\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_hulls_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. EXPORTAR A GDB\n",
    "viviendas.to_file(gdb_out, layer=(fc_viviendas_out + str(minViv)), driver=\"OpenFileGDB\")\n",
    "# cluster_hulls_final.to_file(gdb_out, layer=(fc_clusters_out + str(minViv)), driver=\"OpenFileGDB\")\n",
    "# print(gdb_out, (fc_viviendas_out + str(minViv)))\n",
    "# print(gdb_out, (fc_clusters_out + str(minViv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. EXPORTAR A GDB\n",
    "# viviendas.to_file(gdb_out, layer=(fc_viviendas_out + str(minViv)), driver=\"OpenFileGDB\")\n",
    "cluster_hulls_final.to_file(gdb_out, layer=(fc_clusters_out + str(minViv)), driver=\"OpenFileGDB\")\n",
    "# print(gdb_out, (fc_viviendas_out + str(minViv)))\n",
    "# print(gdb_out, (fc_clusters_out + str(minViv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viviendas.to_file(gdb_out, layer=(fc_viviendas_out + str(minViv) + \"TEST\"), driver=\"OpenFileGDB\")\n",
    "cluster_hulls_final.to_file(gdb_out, layer=(fc_clusters_out + str(minViv) + \"TEST\"), driver=\"OpenFileGDB\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
